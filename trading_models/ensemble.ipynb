{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined_features.csv',index_col=0)\n",
    "df.sort_index(inplace=True)\n",
    "df.dropna(inplace = True)\n",
    "#generate label for training\n",
    "def gen_labels(df,t,threshold):\n",
    "    # Calculate % return on spread t hours later\n",
    "    df['forward_return'] = df['spread'].diff(periods=t)/df['spread']\n",
    "    \n",
    "    #If the return is more than x%, we should have bought, and hence the label is (1)\n",
    "    #If return is less than x%, we should have sold, and hence label is (-1)\n",
    "    #If in between, do nothing (0)\n",
    "    df['output'] = np.select([df['forward_return'] > threshold ,df['forward_return'] < -threshold],[1,-1])\n",
    "    return df\n",
    "\n",
    "df = gen_labels(df,t=24,threshold=0.05)\n",
    "\n",
    "#train and test data\n",
    "split = round(0.8*len(df))\n",
    "train, test = df[:split],df[split:]\n",
    "x_train = train[['vwap','SMA(5)','SMA(10)','12dayEWM','rsi','MACD','mom','mfi','spread']]\n",
    "y_train = train[['output']]\n",
    "\n",
    "x_test = test[['vwap','SMA(5)','SMA(10)','12dayEWM','rsi','MACD','mom','mfi','spread']]\n",
    "y_test = test[['output']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('lr', LogisticRegression(solver='newton-cg',penalty='none',C=0.001, max_iter=5000)))\n",
    "\tlevel0.append(('cart', RandomForestClassifier(bootstrap= True,\n",
    "                             max_depth= 120,\n",
    "                             max_features= 9,\n",
    "                             min_samples_leaf= 5,\n",
    "                             min_samples_split= 10,\n",
    "                             n_estimators=100,\n",
    "                             random_state = 42)))\n",
    "\tlevel0.append(('svm', SVC(C= 10, degree= 2, gamma= 'auto', kernel= 'poly')))\n",
    "\t# define meta learner model\n",
    "\tlevel1 = LogisticRegression()\n",
    "\t# define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = cross_val_score(get_stacking(),x_test,y_test,cv = 5,scoring = 'accuracy')\n",
    "# print(\"The accuracy score of is:\",score.mean())\n",
    "# score = cross_val_score(get_stacking(),x_test,y_test,cv = 5,scoring = 'f1_weighted')\n",
    "# print(\"The f1 score of is:\",score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.84      0.75       178\n",
      "           0       0.73      0.72      0.72       386\n",
      "           1       0.80      0.67      0.73       227\n",
      "\n",
      "    accuracy                           0.73       791\n",
      "   macro avg       0.74      0.74      0.73       791\n",
      "weighted avg       0.74      0.73      0.73       791\n",
      "\n",
      "0.7307206068268015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "stacking_model = get_stacking().fit(x_train,y_train)\n",
    "stacking_y_pred = stacking_model.predict(x_test)\n",
    "print(classification_report(y_test,stacking_y_pred))\n",
    "print(accuracy_score(stacking_y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Max-voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "import pickle\n",
    "lr = LogisticRegression(solver='newton-cg',penalty='none',C=0.001, max_iter=5000)\n",
    "rf=  RandomForestClassifier(bootstrap= True,\n",
    "                             max_depth= 120,\n",
    "                             max_features= 9,\n",
    "                             min_samples_leaf= 5,\n",
    "                             min_samples_split= 10,\n",
    "                             n_estimators=100,\n",
    "                             random_state = 42)\n",
    "svm =  SVC(C= 10, degree= 2, gamma= 'auto', kernel= 'poly')\n",
    "model = VotingClassifier(estimators=[('lr', lr), ('rf', rf), ('svm',svm)], voting='hard')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.49      0.64       178\n",
      "           0       0.68      0.92      0.78       386\n",
      "           1       0.87      0.67      0.76       227\n",
      "\n",
      "    accuracy                           0.75       791\n",
      "   macro avg       0.82      0.69      0.73       791\n",
      "weighted avg       0.79      0.75      0.74       791\n",
      "\n",
      "0.7509481668773704\n"
     ]
    }
   ],
   "source": [
    "model = model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
